# LLM-optimization-using-Advanced-Prompt-Engineering-and-Fine-Tuning-Techniques
Engineered prompts for 3 distinct LLMs to measure inference time and accuracy, employing zero-shot, few-shot, and instruction fine-tuning approaches.

Fine-tuned models using LoRA and PEFT, enhancing question-answering and summarization performance, while optimizing computational efficiency and preserving pre-trained model weights.
